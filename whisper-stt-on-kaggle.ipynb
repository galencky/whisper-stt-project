{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\n!pip install --upgrade google-api-python-client google-auth-httplib2 google-auth-oauthlib\n!pip install --upgrade openai-whisper tqdm google-generativeai requests\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-01T12:27:19.731547Z","iopub.execute_input":"2025-06-01T12:27:19.731892Z","iopub.status.idle":"2025-06-01T12:27:27.145024Z","shell.execute_reply.started":"2025-06-01T12:27:19.731871Z","shell.execute_reply":"2025-06-01T12:27:27.143964Z"},"scrolled":true},"outputs":[{"name":"stdout","text":"Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (2.170.0)\nRequirement already satisfied: google-auth-httplib2 in /usr/local/lib/python3.11/dist-packages (0.2.0)\nRequirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.11/dist-packages (1.2.2)\nRequirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client) (0.22.0)\nRequirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client) (2.40.1)\nRequirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client) (1.34.1)\nRequirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client) (4.1.1)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib) (2.0.0)\nRequirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (1.70.0)\nRequirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (3.20.3)\nRequirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2.32.3)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (5.5.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (0.4.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (4.9.1)\nRequirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client) (3.0.9)\nRequirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.2.2)\nRequirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (0.6.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2025.4.26)\nRequirement already satisfied: openai-whisper in /usr/local/lib/python3.11/dist-packages (20240930)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\nRequirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\nRequirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.60.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (1.26.4)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (2.6.0+cu124)\nRequirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (10.6.0)\nRequirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.9.0)\nRequirement already satisfied: triton>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (3.2.0)\nRequirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\nRequirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (1.34.1)\nRequirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.170.0)\nRequirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.40.1)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (3.20.3)\nRequirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.11.4)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.13.2)\nRequirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.4.26)\nRequirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\nRequirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\nRequirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\nRequirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper) (0.43.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->openai-whisper) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->openai-whisper) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->openai-whisper) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->openai-whisper) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->openai-whisper) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->openai-whisper) (2.4.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.4.0)\nRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2024.11.6)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.18.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\nRequirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.72.0rc1)\nRequirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.49.0rc1)\nRequirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.0.9)\nRequirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->openai-whisper) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->openai-whisper) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->openai-whisper) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->openai-whisper) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->openai-whisper) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->openai-whisper) (2024.2.0)\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"to_be_transcribed = \"1AKnppHssmAwkjBo2EPI8Twf6782hH2xv\"\ntranscribed = \"1AKnppHssmAwkjBo2EPI8Twf6782hH2xv\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T12:27:27.146877Z","iopub.execute_input":"2025-06-01T12:27:27.147237Z","iopub.status.idle":"2025-06-01T12:27:27.151262Z","shell.execute_reply.started":"2025-06-01T12:27:27.147206Z","shell.execute_reply":"2025-06-01T12:27:27.150544Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"import os\nimport json\nfrom kaggle_secrets import UserSecretsClient\nfrom google.oauth2 import service_account\nfrom googleapiclient.discovery import build\n\n# ──────────────────────────────────────────────────────────────────────────────\n# 1. Pull the SERVICE_ACCOUNT JSON from Kaggle Secrets and write it to /kaggle/working\n# ──────────────────────────────────────────────────────────────────────────────\ns = UserSecretsClient()\nsa_json_str = s.get_secret(\"GDRIVE_SA_JSON\")\n\nsa_path = \"/kaggle/working/sa_key.json\"\nwith open(sa_path, \"w\") as f:\n    f.write(sa_json_str)\n\n# ──────────────────────────────────────────────────────────────────────────────\n# 2. Build the Drive client using that file\n# ──────────────────────────────────────────────────────────────────────────────\nSCOPES = [\"https://www.googleapis.com/auth/drive\"]\ncreds = service_account.Credentials.from_service_account_file(sa_path, scopes=SCOPES)\ndrive_service = build(\"drive\", \"v3\", credentials=creds)\n\n# ──────────────────────────────────────────────────────────────────────────────\n# 3. Remove the local service account file for security\n# ──────────────────────────────────────────────────────────────────────────────\nif os.path.exists(sa_path):\n    try:\n        os.remove(sa_path)\n        print(f\"✅ Removal successful: '{sa_path}' has been deleted.\")\n    except Exception as e:\n        print(f\"❌ Removal failed: {e}\")\nelse:\n    print(f\"ℹ️ No such file: '{sa_path}' (nothing to remove).\")\n\n# ──────────────────────────────────────────────────────────────────────────────\n# 4. List files in the shared folder, then set new_files flag accordingly\n# ──────────────────────────────────────────────────────────────────────────────\nFOLDER_ID = to_be_transcribed  # ← replace with your actual folder ID\n\ndef list_files_in_folder(folder_id):\n    query = f\"'{folder_id}' in parents and trashed=false\"\n    files = []\n    page_token = None\n    while True:\n        resp = drive_service.files().list(\n            q=query,\n            spaces=\"drive\",\n            fields=\"nextPageToken, files(id, name)\",\n            pageToken=page_token\n        ).execute()\n        files.extend(resp.get(\"files\", []))\n        page_token = resp.get(\"nextPageToken\", None)\n        if not page_token:\n            break\n    return files\n\nfiles = list_files_in_folder(FOLDER_ID)\n\n# Determine whether new files exist\nif not files:\n    new_files = False\n    print(f\"⚠️ No files found in folder ID = {FOLDER_ID!r}. new_files = False.\")\nelse:\n    new_files = True\n    print(f\"✅ Found {len(files)} file(s) in folder ID = {FOLDER_ID!r}. new_files = True.\")\n    for f in files:\n        print(f\" • {f['name']} (ID={f['id']})\")\n\n# ──────────────────────────────────────────────────────────────────────────────\n# 5. Continue with the rest of the notebook’s logic, using new_files flag\n# ──────────────────────────────────────────────────────────────────────────────\n\n# Example usage:\n#if new_files:\n    # ... perform download/transcription/etc.\n#    pass\n#else:\n    # ... skip processing, or run alternative steps\n#    pass\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T12:27:27.151971Z","iopub.execute_input":"2025-06-01T12:27:27.152138Z","iopub.status.idle":"2025-06-01T12:27:28.686842Z","shell.execute_reply.started":"2025-06-01T12:27:27.152117Z","shell.execute_reply":"2025-06-01T12:27:28.686189Z"}},"outputs":[{"name":"stdout","text":"✅ Removal successful: '/kaggle/working/sa_key.json' has been deleted.\n✅ Found 2 file(s) in folder ID = '1AKnppHssmAwkjBo2EPI8Twf6782hH2xv'. new_files = True.\n • 20230730 OpenHCI presentation.m4a (ID=1CnnASu-V5Ta5GN4k5nQLi-cTrTfoJCVL)\n • 20230810 OpenHCI presentation feedback.m4a (ID=1AV3_V3hTZSTomSziIIEtgYpavmP9uxPr)\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"import datetime, shutil, sys, time\nfrom pathlib import Path\nfrom tqdm import tqdm\nimport whisper\n\n# ──────────────────────────────────────────────────────────────────────────────\n# Assume `new_files` has been set by the previous logic (True/False)\n# ──────────────────────────────────────────────────────────────────────────────\nif not new_files:\n    print(f\"[{datetime.datetime.now():%Y-%m-%d %H:%M:%S}] ⚠️ new_files == False → Skipping transcription.\")\n    # You can add any alternative logic here if needed\nelse:\n    AUDIO_EXT = {'.wav', '.mp3', '.m4a', '.flac', '.ogg', '.webm'}\n\n    def _now():\n        \"\"\"Log-friendly timestamp.\"\"\"\n        return datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n\n    def _fmt_ts(seconds: float) -> str:\n        \"\"\"float seconds → HH:MM:SS.mmm string.\"\"\"\n        h, m = divmod(int(seconds), 3600)\n        m, s = divmod(m, 60)\n        ms = int((seconds - int(seconds)) * 1000)\n        return f\"{h:02d}:{m:02d}:{s:02d}.{ms:03d}\"\n\n    def save_transcript(result: dict, out_path: Path):\n        \"\"\"\n        Write Whisper's segment list to a .txt file.\n        Each line: [start → end] text\n        \"\"\"\n        with open(out_path, \"w\", encoding=\"utf-8\") as f:\n            for seg in result[\"segments\"]:\n                f.write(f\"[{_fmt_ts(seg['start'])} → {_fmt_ts(seg['end'])}] \"\n                        f\"{seg['text'].strip()}\\n\")\n\n    # ─── Ensure a local cache directory in Kaggle working ───────────────────────\n    CACHE_DIR = Path(\"/kaggle/working/whisper_models\")\n    CACHE_DIR.mkdir(parents=True, exist_ok=True)\n\n    # ─── Load Whisper Model, using CACHE_DIR for both load & download ──────────\n    start = time.time()\n    print(f\"[{_now()}] Attempting to load Whisper large-v3 from cache…\")\n    try:\n        model = whisper.load_model(\"large-v3\", download_root=str(CACHE_DIR))\n        print(f\"[{_now()}] Model loaded from cache or downloaded into '{CACHE_DIR}'.\")\n    except Exception as e:\n        print(f\"[{_now()}] ⚠️ Failed to load from cache: {e}\")\n        print(f\"[{_now()}] Downloading Whisper large-v3 into '{CACHE_DIR}'…\")\n        model = whisper.load_model(\"large-v3\", download_root=str(CACHE_DIR))\n        print(f\"[{_now()}] Model downloaded and cached at '{CACHE_DIR}'.\")\n\n    print(f\"[{_now()}] Model ready (took {time.time() - start:.1f} s)\\n\")\n\n    # ─── Set preferred language (or None for autodetect) ───────────────────────\n    PREFERRED_LANGUAGE = \"zh\"  # or None\n    if PREFERRED_LANGUAGE:\n        print(f\"[{_now()}] 🌐 Preferred language set to '{PREFERRED_LANGUAGE}'\")\n    else:\n        print(f\"[{_now()}] 🌐 Using Whisper's automatic language detection\")\n\n    # ─── Gather all audio files from the downloaded folder ─────────────────—\n    INBOX_DIR = Path(\"/kaggle/working/from_google_drive\")\n    TRANSCRIPTS_DIR = Path(\"/kaggle/working/transcription\")\n    TRANSCRIPTS_DIR.mkdir(parents=True, exist_ok=True)\n\n    audio_files = [p for p in INBOX_DIR.rglob(\"*\") if p.suffix.lower() in AUDIO_EXT]\n    total = len(audio_files)\n\n    if total == 0:\n        print(f\"[{_now()}] 📂 No audio files found under {INBOX_DIR}\")\n        print(\"Please place your audio files in /kaggle/working/from_google_drive and re-run.\")\n    else:\n        print(f\"[{_now()}] 🎧 Found {total} audio file(s) under {INBOX_DIR}\")\n\n        # ─── Transcription loop with tqdm progress bar over files ───────────────\n        for audio in tqdm(audio_files, desc=\"Transcribing files\", unit=\"file\"):\n            tqdm.set_description(f\"Transcribing: {audio.name}\")\n\n            # Build Whisper kwargs\n            kwargs = {\"word_timestamps\": True, \"verbose\": False}\n            if PREFERRED_LANGUAGE:\n                kwargs[\"language\"] = PREFERRED_LANGUAGE\n\n            # Transcribe\n            result = model.transcribe(str(audio), **kwargs)\n\n            # Save transcript with same stem under TRANSCRIPTS_DIR\n            out_txt = TRANSCRIPTS_DIR / f\"{audio.stem}.txt\"\n            save_transcript(result, out_txt)\n\n        print(f\"\\n[{_now()}] 🎉 All transcription jobs finished! Transcripts are in {TRANSCRIPTS_DIR}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T12:27:28.688208Z","iopub.execute_input":"2025-06-01T12:27:28.688642Z","iopub.status.idle":"2025-06-01T12:27:55.082274Z","shell.execute_reply.started":"2025-06-01T12:27:28.688624Z","shell.execute_reply":"2025-06-01T12:27:55.081410Z"},"_kg_hide-input":false},"outputs":[{"name":"stdout","text":"[2025-06-01 12:27:28] Attempting to load Whisper large-v3 from cache…\n[2025-06-01 12:27:55] Model loaded from cache or downloaded into '/kaggle/working/whisper_models'.\n[2025-06-01 12:27:55] Model ready (took 26.4 s)\n\n[2025-06-01 12:27:55] 🌐 Preferred language set to 'zh'\n[2025-06-01 12:27:55] 📂 No audio files found under /kaggle/working/from_google_drive\nPlease place your audio files in /kaggle/working/from_google_drive and re-run.\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"import os\nimport io\nfrom googleapiclient.http import MediaIoBaseDownload\n\n# ──────────────────────────────────────────────────────────────────────────────\n# 1. Replace this with your actual Drive folder ID (the folder containing all files to download)\nTO_BE_TRANSCRIBED_ID = to_be_transcribed\n\n# 2. Create a local folder under /kaggle/working\nlocal_root = \"/kaggle/working/from_google_drive\"\nos.makedirs(local_root, exist_ok=True)\n\n# ──────────────────────────────────────────────────────────────────────────────\n# 3. List all non-folder files directly under TO_BE_TRANSCRIBED_ID\nquery_files = (\n    f\"'{TO_BE_TRANSCRIBED_ID}' in parents and \"\n    \"trashed = false and \"\n    \"mimeType != 'application/vnd.google-apps.folder'\"\n)\nresponse = drive_service.files().list(\n    q=query_files,\n    spaces=\"drive\",\n    fields=\"files(id, name)\"\n).execute()\nfiles = response.get(\"files\", [])\n\nif not files:\n    print(f\"⚠️ No files found in folder ID = {TO_BE_TRANSCRIBED_ID!r}, skip downloading.\")\nelse:\n    print(f\"🔎 Found {len(files)} file(s) in folder ID = {TO_BE_TRANSCRIBED_ID!r}:\")\n    for f in files:\n        print(f\" • {f['name']}  (ID = {f['id']})\")\n\n# ──────────────────────────────────────────────────────────────────────────────\n# 4. Download each file into /kaggle/working/from_google_drive\nfor f in files:\n    file_id   = f[\"id\"]\n    file_name = f[\"name\"]\n    dest_path = os.path.join(local_root, file_name)\n\n    try:\n        request = drive_service.files().get_media(fileId=file_id)\n        fh = io.FileIO(dest_path, mode=\"wb\")\n        downloader = MediaIoBaseDownload(fh, request)\n        done = False\n        print(f\"⬇️  Downloading {file_name!r} …\")\n        while not done:\n            status, done = downloader.next_chunk()\n        fh.close()\n        print(f\"✅ Saved to {dest_path}\")\n    except Exception as e:\n        print(f\"❌ Error downloading {file_name!r}: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T12:27:55.082981Z","iopub.execute_input":"2025-06-01T12:27:55.083192Z","iopub.status.idle":"2025-06-01T12:28:04.835041Z","shell.execute_reply.started":"2025-06-01T12:27:55.083176Z","shell.execute_reply":"2025-06-01T12:28:04.834269Z"}},"outputs":[{"name":"stdout","text":"🔎 Found 2 file(s) in folder ID = '1AKnppHssmAwkjBo2EPI8Twf6782hH2xv':\n • 20230730 OpenHCI presentation.m4a  (ID = 1CnnASu-V5Ta5GN4k5nQLi-cTrTfoJCVL)\n • 20230810 OpenHCI presentation feedback.m4a  (ID = 1AV3_V3hTZSTomSziIIEtgYpavmP9uxPr)\n⬇️  Downloading '20230730 OpenHCI presentation.m4a' …\n✅ Saved to /kaggle/working/from_google_drive/20230730 OpenHCI presentation.m4a\n⬇️  Downloading '20230810 OpenHCI presentation feedback.m4a' …\n✅ Saved to /kaggle/working/from_google_drive/20230810 OpenHCI presentation feedback.m4a\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"from pathlib import Path\nimport whisper\nimport datetime\nfrom tqdm import tqdm\n\nif not new_files:\n    print(f\"[{datetime.datetime.now():%Y-%m-%d %H:%M:%S}] ⚠️ new_files == False → Skipping transcription.\")\nelse:\n    PREFERRED_LANGUAGE = \"zh\"  # or None\n\n    if PREFERRED_LANGUAGE:\n        print(f\"[{datetime.datetime.now():%Y-%m-%d %H:%M:%S}] 🌐 Preferred language set to '{PREFERRED_LANGUAGE}'\")\n    else:\n        print(f\"[{datetime.datetime.now():%Y-%m-%d %H:%M:%S}] 🌐 Using Whisper's automatic language detection\")\n\n    INBOX_DIR       = Path(\"/kaggle/working/from_google_drive\")\n    TRANSCRIPTS_DIR = Path(\"/kaggle/working/transcription\")\n    TRANSCRIPTS_DIR.mkdir(parents=True, exist_ok=True)\n\n    audio_files = [\n        p for p in INBOX_DIR.rglob(\"*\")\n        if p.suffix.lower() in AUDIO_EXT\n    ]\n    total = len(audio_files)\n\n    if total == 0:\n        print(f\"[{datetime.datetime.now():%Y-%m-%d %H:%M:%S}] 📂 No audio files found under {INBOX_DIR}\")\n        print(\"Please place your audio files in /kaggle/working/from_google_drive and re-run.\")\n    else:\n        print(f\"[{datetime.datetime.now():%Y-%m-%d %H:%M:%S}] 🎧 Found {total} audio file(s) under {INBOX_DIR}\")\n\n        with tqdm(audio_files, desc=\"Transcribing files\", unit=\"file\") as pbar:\n            for audio in pbar:\n                pbar.set_postfix_str(f\"Now: {audio.name}\")\n\n                kwargs = {\"word_timestamps\": True, \"verbose\": False}\n                if PREFERRED_LANGUAGE:\n                    kwargs[\"language\"] = PREFERRED_LANGUAGE\n\n                result = model.transcribe(str(audio), **kwargs)\n                out_txt = TRANSCRIPTS_DIR / f\"{audio.stem}.txt\"\n                save_transcript(result, out_txt)\n\n        print(f\"\\n[{datetime.datetime.now():%Y-%m-%d %H:%M:%S}] 🎉 All transcription jobs finished! Transcripts are in {TRANSCRIPTS_DIR}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T12:28:04.835986Z","iopub.execute_input":"2025-06-01T12:28:04.836245Z","iopub.status.idle":"2025-06-01T12:33:58.437818Z","shell.execute_reply.started":"2025-06-01T12:28:04.836224Z","shell.execute_reply":"2025-06-01T12:33:58.437031Z"},"_kg_hide-input":true,"scrolled":true},"outputs":[{"name":"stdout","text":"[2025-06-01 12:28:04] 🌐 Preferred language set to 'zh'\n[2025-06-01 12:28:04] 🎧 Found 2 audio file(s) under /kaggle/working/from_google_drive\n","output_type":"stream"},{"name":"stderr","text":"Transcribing files:   0%|          | 0/2 [00:00<?, ?file/s, Now: 20230730 OpenHCI presentation.m4a]\n  0%|          | 0/95178 [00:00<?, ?frames/s]\u001b[A\n  3%|▎         | 2814/95178 [00:05<03:02, 505.06frames/s]\u001b[A\n  6%|▌         | 5758/95178 [00:12<03:15, 458.00frames/s]\u001b[A\n  9%|▉         | 8650/95178 [00:18<03:04, 469.40frames/s]\u001b[A\n 12%|█▏        | 11650/95178 [00:24<02:57, 471.52frames/s]\u001b[A\n 15%|█▌        | 14650/95178 [00:31<02:53, 463.29frames/s]\u001b[A\n 19%|█▊        | 17650/95178 [00:37<02:42, 478.39frames/s]\u001b[A\n 22%|██▏       | 20570/95178 [00:42<02:31, 492.88frames/s]\u001b[A\n 25%|██▍       | 23570/95178 [00:48<02:22, 501.44frames/s]\u001b[A\n 28%|██▊       | 26516/95178 [00:54<02:16, 504.50frames/s]\u001b[A\n 31%|███       | 29516/95178 [00:59<02:07, 513.80frames/s]\u001b[A\n 34%|███▍      | 32516/95178 [01:05<02:01, 517.39frames/s]\u001b[A\n 37%|███▋      | 35516/95178 [01:10<01:48, 551.73frames/s]\u001b[A\n 40%|████      | 38516/95178 [01:13<01:32, 613.76frames/s]\u001b[A\n 43%|████▎     | 41272/95178 [01:19<01:32, 579.82frames/s]\u001b[A\n 47%|████▋     | 44270/95178 [01:25<01:34, 537.46frames/s]\u001b[A\n 50%|████▉     | 47270/95178 [01:30<01:25, 560.45frames/s]\u001b[A\n 53%|█████▎    | 50268/95178 [01:36<01:23, 539.63frames/s]\u001b[A\n 55%|█████▍    | 52320/95178 [01:42<01:28, 485.41frames/s]\u001b[A\n 55%|█████▍    | 52320/95178 [01:54<01:28, 485.41frames/s]\u001b[A\n 58%|█████▊    | 55284/95178 [02:08<02:47, 238.30frames/s]\u001b[A\n 61%|██████    | 57824/95178 [02:13<02:13, 279.66frames/s]\u001b[A\n 64%|██████▍   | 60824/95178 [02:17<01:40, 341.08frames/s]\u001b[A\n 67%|██████▋   | 63824/95178 [02:23<01:21, 385.62frames/s]\u001b[A\n 70%|███████   | 66698/95178 [02:29<01:09, 411.99frames/s]\u001b[A\n 73%|███████▎  | 69696/95178 [02:35<00:57, 439.84frames/s]\u001b[A\n 76%|███████▋  | 72696/95178 [02:41<00:49, 453.26frames/s]\u001b[A\n 79%|███████▉  | 75636/95178 [02:47<00:41, 468.78frames/s]\u001b[A\n 83%|████████▎ | 78636/95178 [03:02<00:50, 330.76frames/s]\u001b[A\n 86%|████████▌ | 81636/95178 [03:07<00:35, 379.45frames/s]\u001b[A\n 89%|████████▉ | 84492/95178 [03:13<00:26, 396.52frames/s]\u001b[A\n 92%|█████████▏| 87384/95178 [03:20<00:19, 406.12frames/s]\u001b[A\n 95%|█████████▍| 90212/95178 [03:27<00:12, 406.98frames/s]\u001b[A\n 98%|█████████▊| 93212/95178 [03:34<00:04, 417.68frames/s]\u001b[A\n100%|██████████| 95178/95178 [03:37<00:00, 436.62frames/s]\u001b[A\nTranscribing files:  50%|█████     | 1/2 [03:39<03:39, 219.87s/file, Now: 20230810 OpenHCI presentation feedback.m4a]\n  0%|          | 0/65158 [00:00<?, ?frames/s]\u001b[A\n  5%|▍         | 2962/65158 [00:05<01:52, 550.50frames/s]\u001b[A\n  9%|▉         | 5962/65158 [00:11<01:52, 524.36frames/s]\u001b[A\n 14%|█▎        | 8800/65158 [00:16<01:46, 529.63frames/s]\u001b[A\n 18%|█▊        | 11710/65158 [00:22<01:46, 500.79frames/s]\u001b[A\n 23%|██▎       | 14710/65158 [00:29<01:46, 475.51frames/s]\u001b[A\n 27%|██▋       | 17710/65158 [00:35<01:39, 477.95frames/s]\u001b[A\n 32%|███▏      | 20710/65158 [00:39<01:21, 546.28frames/s]\u001b[A\n 36%|███▋      | 23710/65158 [00:44<01:13, 565.58frames/s]\u001b[A\n 41%|████      | 26710/65158 [00:51<01:12, 532.37frames/s]\u001b[A\n 46%|████▌     | 29710/65158 [00:55<01:03, 556.78frames/s]\u001b[A\n 50%|█████     | 32586/65158 [01:00<00:56, 575.82frames/s]\u001b[A\n 54%|█████▍    | 35412/65158 [01:05<00:52, 562.30frames/s]\u001b[A\n 59%|█████▉    | 38284/65158 [01:10<00:46, 582.05frames/s]\u001b[A\n 63%|██████▎   | 41284/65158 [01:16<00:44, 536.00frames/s]\u001b[A\n 68%|██████▊   | 44284/65158 [01:24<00:42, 486.51frames/s]\u001b[A\n 73%|███████▎  | 47246/65158 [01:31<00:38, 459.95frames/s]\u001b[A\n 77%|███████▋  | 50182/65158 [01:37<00:32, 461.85frames/s]\u001b[A\n 82%|████████▏ | 53120/65158 [01:44<00:26, 455.05frames/s]\u001b[A\n 86%|████████▌ | 56120/65158 [01:51<00:20, 451.03frames/s]\u001b[A\n 91%|█████████ | 59120/65158 [01:57<00:13, 461.24frames/s]\u001b[A\n 95%|█████████▌| 62120/65158 [02:03<00:06, 481.64frames/s]\u001b[A\n100%|██████████| 65158/65158 [02:12<00:00, 491.68frames/s]\u001b[A\nTranscribing files: 100%|██████████| 2/2 [05:53<00:00, 176.79s/file, Now: 20230810 OpenHCI presentation feedback.m4a]","output_type":"stream"},{"name":"stdout","text":"\n[2025-06-01 12:33:58] 🎉 All transcription jobs finished! Transcripts are in /kaggle/working/transcription\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"import re\nfrom datetime import timedelta, datetime\nfrom pathlib import Path\n\n# Regex to match lines like: [HH:MM:SS.mmm → HH:MM:SS.mmm] text\ntimestamp_pattern = re.compile(\n    r\"\\[(\\d{2}:\\d{2}:\\d{2}\\.\\d{3})\\s*→\\s*(\\d{2}:\\d{2}:\\d{2}\\.\\d{3})\\]\\s*(.*)\"\n)\n\ndef parse_time(s: str) -> timedelta:\n    \"\"\"Convert 'HH:MM:SS.mmm' → timedelta.\"\"\"\n    h, m, rest = s.split(\":\")\n    s_part, ms = rest.split(\".\")\n    return timedelta(hours=int(h), minutes=int(m),\n                     seconds=int(s_part), milliseconds=int(ms))\n\ndef process_transcript(text: str) -> str:\n    \"\"\"\n    Group segments every 5 minutes. Output format:\n      [HH:MM:SS.mmm]\n      <concatenated text for that 5-minute chunk>\n\n    Blank line between chunks.\n    \"\"\"\n    lines = text.splitlines()\n    segments = []\n    for line in lines:\n        m = timestamp_pattern.match(line)\n        if m:\n            start_ts, end_ts, content = m.groups()\n            segments.append((parse_time(start_ts), start_ts, content.strip()))\n\n    if not segments:\n        return \"\"  # no timed segments found\n\n    result = []\n    buffer = \"\"\n    last_mark_minute = None\n\n    for ts, start_ts_str, content in segments:\n        curr_minute = int(ts.total_seconds() // 300)  # chunk index (every 300 sec)\n        if last_mark_minute is None or curr_minute != last_mark_minute:\n            if buffer:\n                result.append(buffer.strip())\n                buffer = \"\"\n            result.append(f\"[{start_ts_str}]\")\n            last_mark_minute = curr_minute\n        buffer += content + \" \"\n\n    if buffer:\n        result.append(buffer.strip())\n\n    # Combine into blocks of 3 lines: timestamp, paragraph, blank line\n    output = []\n    for i in range(0, len(result), 2):\n        if i + 1 < len(result):\n            output.append(result[i])   # timestamp line\n            output.append(result[i+1]) # text for that block\n            output.append(\"\")          # blank line\n\n    return \"\\n\".join(output).strip()\n\n# ─── Batch processing for Kaggle ─────────────\nTRANSCRIPTS_DIR = Path(\"/kaggle/working/transcription\")\nPARSED_DIR = Path(\"/kaggle/working/parsed\")\nPARSED_DIR.mkdir(parents=True, exist_ok=True)\n\ntxt_files = list(TRANSCRIPTS_DIR.glob(\"*.txt\"))\nif not txt_files:\n    print(f\"[{datetime.now():%Y-%m-%d %H:%M:%S}] ⚠️ No .txt files found in {TRANSCRIPTS_DIR}. Skipping parsing.\")\nelse:\n    for txtfile in txt_files:\n        with txtfile.open(encoding=\"utf-8\") as f:\n            text = f.read()\n\n        processed = process_transcript(text)\n        out_path = PARSED_DIR / txtfile.name.replace(\".txt\", \"_parsed.txt\")\n\n        with out_path.open(\"w\", encoding=\"utf-8\") as f:\n            f.write(processed)\n        print(f\"🔧 Processed {txtfile.name} → {out_path.name}\")\n\n    print(\"\\n✅ All transcripts parsed.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T12:33:58.438804Z","iopub.execute_input":"2025-06-01T12:33:58.439208Z","iopub.status.idle":"2025-06-01T12:33:58.454462Z","shell.execute_reply.started":"2025-06-01T12:33:58.439151Z","shell.execute_reply":"2025-06-01T12:33:58.453696Z"}},"outputs":[{"name":"stdout","text":"🔧 Processed 20230730 OpenHCI presentation.txt → 20230730 OpenHCI presentation_parsed.txt\n🔧 Processed 20230810 OpenHCI presentation feedback.txt → 20230810 OpenHCI presentation feedback_parsed.txt\n\n✅ All transcripts parsed.\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"from googleapiclient.discovery import build\n\nDOC_ID = '1p44XUpBu7lPjyux4eANd_9FHT5F1UDbgUyx7q6Libvk'\n\ndef get_doc_text(doc_id: str, creds) -> str:\n    service = build('docs', 'v1', credentials=creds)\n    doc = service.documents().get(documentId=doc_id).execute()\n    text = []\n    for element in doc.get('body', {}).get('content', []):\n        if 'paragraph' in element:\n            for run in element['paragraph'].get('elements', []):\n                txt = run.get('textRun', {}).get('content')\n                if txt:\n                    text.append(txt)\n    return ''.join(text).strip()\n\n# Retrieve the system prompt from the Google Doc\nSYSTEM_PROMPT = get_doc_text(DOC_ID, creds)\nprint(\"[INFO] SYSTEM_PROMPT loaded from Google Doc. Preview:\\n\", SYSTEM_PROMPT)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T12:33:58.455255Z","iopub.execute_input":"2025-06-01T12:33:58.455524Z","iopub.status.idle":"2025-06-01T12:34:00.105844Z","shell.execute_reply.started":"2025-06-01T12:33:58.455502Z","shell.execute_reply":"2025-06-01T12:34:00.105181Z"},"scrolled":true},"outputs":[{"name":"stdout","text":"[INFO] SYSTEM_PROMPT loaded from Google Doc. Preview:\n ## System Prompt\n\nYou are tasked with summarizing a speech provided in its original language. Create a concise, structured summary using clear and informative markdown formatting. Follow the outline and format precisely. You may use markdown tables, bullet points, paragraphs, or a combination as appropriate.\n\n## Summary Structure\n\n### Title\n\nProvide a concise, relevant title reflecting the key theme or message of the speech.\nPlease make sure the title starts with a # to be recognized as title.\n\n# Title\n\n### Speaker\n\n* **Name**: \\\\[Speaker's Name]\n* **Affiliation/Role**: \\\\[Speaker’s Affiliation or Role, if known]\n* **Event**: \\\\[Event or occasion where the speech was given, if applicable]\n* **Date**: \\\\[Date of the speech, if available]\n\n### Overview\n\nProvide a short paragraph summarizing the overall purpose and main points of the speech.\n\n### Key Points\n\nSummarize each major point clearly. You may use markdown tables, bullet points, or paragraphs as needed:\n\n* **Key Point 1**: Brief description with supporting details.\n* **Key Point 2**: Brief description with supporting details.\n* Additional points as necessary.\n\nOr alternatively, use a markdown table.\n\n### Notable Quotes\n\nInclude one or two significant quotes from the speech, if available, highlighting central themes or key statements made by the speaker:\n\n* *\"Quote 1...\"*\n* *\"Quote 2...\"*\n\n### Audience Reaction\n\nBriefly describe audience reactions, if mentioned or apparent (e.g., applause, questions raised, notable silence).\n\n### Conclusion\n\nSummarize briefly how the speaker concluded their speech and highlight any key takeaway messages.\n\n---\n\nEnsure clarity, accuracy, and conciseness in the summary, preserving essential context and meaning.\nPlease summarize using the native language of the speech.\n\"\"\"\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"from pathlib import Path\nfrom kaggle_secrets import UserSecretsClient\nimport google.generativeai as genai\n\n# Retrieve Gemini API key from Kaggle secrets\ns = UserSecretsClient()\napi_key = s.get_secret(\"GEMINI_API_KEY\")\nif api_key is None:\n    raise ValueError(\"GEMINI_API_KEY not found in Kaggle secrets! Add it via Add-ons → Secrets.\")\n\ngenai.configure(api_key=api_key)\n\ndef generate_summary_with_gemini(speech_text: str, system_prompt: str) -> str:\n    model = genai.GenerativeModel(\"gemini-2.5-flash-preview-05-20\")\n    full_prompt = system_prompt.strip() + \"\\n\\n\" + speech_text.strip()\n    try:\n        response = model.generate_content(\n            full_prompt,\n            generation_config=genai.types.GenerationConfig(temperature=0.5),\n            stream=False,\n        )\n        return response.text\n    except Exception as e:\n        print(f\"[ERROR] Gemini API error: {e}\")\n        return None\n\ndef process_all_txt_files(parsed_dir: Path, markdown_dir: Path, system_prompt: str):\n    parsed_dir = Path(parsed_dir)\n    markdown_dir = Path(markdown_dir)\n    markdown_dir.mkdir(parents=True, exist_ok=True)\n\n    txt_files = list(parsed_dir.glob(\"*.txt\"))\n    if not txt_files:\n        print(f\"[INFO] No parsed .txt files found in {parsed_dir}. Skipping summarization.\")\n        return\n\n    print(f\"[INFO] Found {len(txt_files)} .txt files in {parsed_dir}\")\n\n    for txt_path in txt_files:\n        print(f\"\\n[INFO] Processing: {txt_path.name}\")\n        try:\n            with open(txt_path, \"r\", encoding=\"utf-8\") as f:\n                speech_text = f.read().strip()\n        except Exception as e:\n            print(f\"[ERROR] Could not read {txt_path}: {e}\")\n            continue\n\n        if not speech_text:\n            print(f\"[WARNING] {txt_path.name} is empty, skipping.\")\n            continue\n\n        summary_md = generate_summary_with_gemini(speech_text, system_prompt)\n        if summary_md is None:\n            print(f\"[ERROR] Gemini API failed for {txt_path.name}, skipping.\")\n            continue\n\n        md_path = markdown_dir / (txt_path.stem.replace(\"_parsed\", \"\") + \".md\")\n\n        try:\n            with open(md_path, \"w\", encoding=\"utf-8\") as f:\n                f.write(summary_md)\n            print(f\"[INFO] Saved summary → {md_path.name}\")\n        except Exception as e:\n            print(f\"[ERROR] Could not save {md_path}: {e}\")\n\n# Set your input/output directories and system prompt\nPARSED_DIR = Path(\"/kaggle/working/parsed\")\nMARKDOWN_DIR = Path(\"/kaggle/working/markdown\")\n# SYSTEM_PROMPT = ... # (get from your Google Doc as before)\n\n# Only run if there are files to process\nif list(PARSED_DIR.glob(\"*.txt\")):\n    process_all_txt_files(PARSED_DIR, MARKDOWN_DIR, SYSTEM_PROMPT)\n    print(\"\\n✅ All summaries generated.\")\nelse:\n    print(f\"[INFO] No .txt files found in {PARSED_DIR}, nothing to summarize.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T12:34:00.106773Z","iopub.execute_input":"2025-06-01T12:34:00.107077Z","iopub.status.idle":"2025-06-01T12:34:31.351165Z","shell.execute_reply.started":"2025-06-01T12:34:00.107052Z","shell.execute_reply":"2025-06-01T12:34:31.350547Z"}},"outputs":[{"name":"stdout","text":"[INFO] Found 2 .txt files in /kaggle/working/parsed\n\n[INFO] Processing: 20230810 OpenHCI presentation feedback_parsed.txt\n[INFO] Saved summary → 20230810 OpenHCI presentation feedback.md\n\n[INFO] Processing: 20230730 OpenHCI presentation_parsed.txt\n[INFO] Saved summary → 20230730 OpenHCI presentation.md\n\n✅ All summaries generated.\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"import requests\nimport shutil\nfrom pathlib import Path\nfrom kaggle_secrets import UserSecretsClient\n\n# ─── Retrieve HackMD token from Kaggle secrets ───────────────────────────\ns = UserSecretsClient()\nhackmd_token = s.get_secret(\"HACKMD_TOKEN\")\nif hackmd_token is None:\n    raise ValueError(\"HACKMD_TOKEN not found in Kaggle secrets! Add it via Add-ons → Secrets.\")\n\ndef upload_to_hackmd(md_content: str, filename: str, api_token: str) -> dict:\n    \"\"\"\n    Uploads a single markdown string to HackMD. Returns {\"title\":..., \"url\":...} on success.\n    \"\"\"\n    # Derive a clean title from the filename\n    if filename.endswith('.md'):\n        filename = filename[:-3]\n    raw_title = filename.replace('_parsed', '').strip()\n    title = raw_title.replace('_', ' ').strip()\n\n    # Ensure there's a top-level heading\n    md_lines = md_content.lstrip().splitlines()\n    if not md_lines or not md_lines[0].strip().startswith(\"# \"):\n        md_content = f\"# {title}\\n\\n\" + md_content.lstrip()\n    else:\n        md_lines[0] = f\"# {title}\"\n        md_content = \"\\n\".join(md_lines)\n\n    # Append hashtag if missing\n    hashtag = \"#whisper-stt-project\"\n    content_lines = md_content.rstrip().splitlines()\n    if not any(line.strip() == hashtag for line in content_lines[-3:]):\n        md_content = md_content.rstrip() + \"\\n\\n\" + hashtag + \"\\n\"\n\n    url = \"https://api.hackmd.io/v1/notes\"\n    headers = {\n        \"Authorization\": f\"Bearer {api_token}\",\n        \"Content-Type\": \"application/json\"\n    }\n    data = {\n        \"title\": title,\n        \"content\": md_content,\n        \"readPermission\": \"guest\",\n        \"writePermission\": \"signed_in\"\n    }\n    response = requests.post(url, headers=headers, json=data)\n    if response.ok:\n        note_id = response.json().get(\"id\")\n        shared_url = f\"https://hackmd.io/{note_id}\"\n        print(f\"[INFO] Uploaded to HackMD: {shared_url}\")\n        return {\"title\": title, \"url\": shared_url}\n    else:\n        print(f\"[ERROR] HackMD upload failed for {filename}: {response.status_code} {response.text}\")\n        return None\n\ndef batch_upload_markdown_and_move(markdown_dir: Path, uploaded_dir: Path, hackmd_token: str) -> list:\n    \"\"\"\n    For each .md in markdown_dir: upload via upload_to_hackmd → move file to uploaded_dir.\n    Returns list of {\"title\":..., \"url\":...}.\n    \"\"\"\n    markdown_dir = Path(markdown_dir)\n    uploaded_dir = Path(uploaded_dir)\n    uploaded_dir.mkdir(parents=True, exist_ok=True)\n\n    md_files = list(markdown_dir.glob(\"*.md\"))\n    if not md_files:\n        print(f\"[INFO] No markdown files found in {markdown_dir}, skipping upload.\")\n        return []\n\n    print(f\"[INFO] Found {len(md_files)} markdown files to upload.\")\n\n    shared_links = []\n    for md_file in md_files:\n        print(f\"[INFO] Processing: {md_file.name}\")\n        try:\n            with open(md_file, \"r\", encoding=\"utf-8\") as f:\n                md_content = f.read()\n        except Exception as e:\n            print(f\"[ERROR] Could not read {md_file.name}: {e}\")\n            continue\n\n        result = upload_to_hackmd(md_content, md_file.name, hackmd_token)\n        if result:\n            shared_links.append(result)\n            dest_file = uploaded_dir / md_file.name\n            try:\n                shutil.move(str(md_file), dest_file)\n                print(f\"[INFO] Moved {md_file.name} → {dest_file}\")\n            except Exception as e:\n                print(f\"[ERROR] Failed to move {md_file.name}: {e}\")\n    return shared_links\n\n# ─── Set directories and run HackMD upload if there are files ──────────\nMARKDOWN_DIR = Path(\"/kaggle/working/markdown\")\nUPLOADED_DIR = Path(\"/kaggle/working/uploaded\")\n\nif list(MARKDOWN_DIR.glob(\"*.md\")):\n    shared_links = batch_upload_markdown_and_move(MARKDOWN_DIR, UPLOADED_DIR, hackmd_token)\n    print(\"\\n✅ All markdown files uploaded to HackMD.\")\nelse:\n    print(f\"[INFO] No .md files found in {MARKDOWN_DIR}, nothing to upload.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T12:34:31.352845Z","iopub.execute_input":"2025-06-01T12:34:31.353065Z","iopub.status.idle":"2025-06-01T12:34:32.559080Z","shell.execute_reply.started":"2025-06-01T12:34:31.353047Z","shell.execute_reply":"2025-06-01T12:34:32.558317Z"}},"outputs":[{"name":"stdout","text":"[INFO] Found 2 markdown files to upload.\n[INFO] Processing: 20230730 OpenHCI presentation.md\n[INFO] Uploaded to HackMD: https://hackmd.io/B3tbAXfyR4mt-ZSwjbx1zQ\n[INFO] Moved 20230730 OpenHCI presentation.md → /kaggle/working/uploaded/20230730 OpenHCI presentation.md\n[INFO] Processing: 20230810 OpenHCI presentation feedback.md\n[INFO] Uploaded to HackMD: https://hackmd.io/dnuWXreWSiGDWSxF2GLUBw\n[INFO] Moved 20230810 OpenHCI presentation feedback.md → /kaggle/working/uploaded/20230810 OpenHCI presentation feedback.md\n\n✅ All markdown files uploaded to HackMD.\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"# ╔══════════════════════════════════════════════════════════════════╗\n# 0) CONSTANT GOOGLE-DRIVE IDS (do NOT change names)                 #\n# ╚══════════════════════════════════════════════════════════════════╝\nINBOX_ID        = \"1AKnppHssmAwkjBo2EPI8Twf6782hH2xv\"  # to_be_transcribed\nARCHIVE_ID      = \"1iuVCOQ6dpg0tff6bHxmUpl4WDIhVybWO\"  # transcribed\nPROCESSED_ID    = \"1zpXQm4PKSD2PXSxmK3Q45VH2wSDbTGcr\"  # processed data (text/md)\n\n# ╔══════════════════════════════════════════════════════════════════╗\n# 1) LOCAL WORKING PATHS                                             #\n# ╚══════════════════════════════════════════════════════════════════╝\nfrom pathlib import Path, PurePath\nimport shutil, datetime\nfrom googleapiclient.discovery import build\nfrom googleapiclient.http import MediaFileUpload\nfrom googleapiclient.errors import HttpError\n\nWORKING      = Path(\"/kaggle/working\")\nTRANS_DIR    = WORKING / \"transcription\"\nPARSED_DIR   = WORKING / \"parsed\"\nUPLOADED_MD  = WORKING / \"uploaded\"            # markdown from HackMD step\nAUDIO_LOCAL  = WORKING / \"from_google_drive\"   # downloaded audio\n\ndrive = build(\"drive\", \"v3\", credentials=creds)\n\ndef log(msg): print(f\"[{datetime.datetime.now():%H:%M:%S}] {msg}\")\n\n# ╔══════════════════════════════════════════════════════════════════╗\n# 2) HELPERS                                                         #\n# ╚══════════════════════════════════════════════════════════════════╝\ndef ensure_subfolder(parent_id: str, name: str) -> str:\n    \"\"\"Return id of subfolder 'name' under parent, creating if absent.\"\"\"\n    q = (f\"'{parent_id}' in parents and mimeType='application/vnd.google-apps.folder' \"\n         f\"and name='{name}' and trashed=false\")\n    res = drive.files().list(q=q, spaces=\"drive\", fields=\"files(id)\").execute()\n    if res[\"files\"]:\n        return res[\"files\"][0][\"id\"]\n    meta = {\"name\": name,\n            \"mimeType\": \"application/vnd.google-apps.folder\",\n            \"parents\": [parent_id]}\n    return drive.files().create(body=meta, fields=\"id\").execute()[\"id\"]\n\ndef upload_file(local: Path, parent_id: str):\n    media = MediaFileUpload(local, resumable=False)\n    meta  = {\"name\": local.name, \"parents\": [parent_id]}\n    drive.files().create(body=meta, media_body=media, fields=\"id\").execute()\n    log(f\"  ↳ uploaded {local.name}\")\n\ndef move_audio(audio_name: str):\n# Move one audio file (exact name) from inbox → archive; silent if not found.\n    q = (f\"'{INBOX_ID}' in parents and name='{audio_name}' and trashed=false\")\n    res = drive.files().list(\n        q=q, spaces=\"drive\", fields=\"files(id)\"\n    ).execute().get(\"files\", [])\n    \n    if not res:\n        return                              # silent if not found\n    fid = res[0][\"id\"]\n    drive.files().update(\n        fileId=fid,\n        addParents=ARCHIVE_ID,\n        removeParents=INBOX_ID,\n        fields=\"id\"\n    ).execute()\n    log(f\"  ↳ moved {audio_name} → transcribed\")\n\n# ╔══════════════════════════════════════════════════════════════════╗\n# 3) PROCESS MARKDOWN FILES                                          #\n# ╚══════════════════════════════════════════════════════════════════╝\nmd_files = list(UPLOADED_MD.glob(\"*.md\"))\nif not md_files:\n    log(\"ℹ️  No markdown files in /uploaded – nothing to sync.\")\nelse:\n    for md in md_files:\n        stem = md.stem\n        folder_id = ensure_subfolder(PROCESSED_ID, stem)\n        log(f\"📂 Drive subfolder '{stem}' (id {folder_id})\")\n\n        txt_path    = TRANS_DIR  / f\"{stem}.txt\"\n        parsed_path = PARSED_DIR / f\"{stem}_parsed.txt\"\n\n        for p in (txt_path, parsed_path, md):\n            if p.exists():\n                upload_file(p, folder_id)\n\n        # Move corresponding audio (same base name, keep original extension)\n        for audio_local in AUDIO_LOCAL.glob(f\"{stem}.*\"):\n            if audio_local.is_file():\n                move_audio(audio_local.name)\n                break   # move only first match\n\n        # Verify contents\n        present = {f[\"name\"] for f in drive.files().list(\n            q=f\"'{folder_id}' in parents and trashed=false\",\n            spaces=\"drive\", fields=\"files(name)\").execute()[\"files\"]}\n        expected = {txt_path.name, parsed_path.name, md.name}\n        if expected - present:\n            log(f\"  ✖ missing {expected - present}\")\n        else:\n            log(\"  ✅ files verified\")\n\n        md.unlink(missing_ok=True)   # remove local markdown\n\n# ╔══════════════════════════════════════════════════════════════════╗\n# 4) MOVE EXTRA AUDIO BASED ON LOCAL COPIES (if any)                 #\n# ╚══════════════════════════════════════════════════════════════════╝\nfor audio_local in AUDIO_LOCAL.glob(\"*\"):\n    if audio_local.is_file():\n        move_audio(audio_local.name)\n\n# ╔══════════════════════════════════════════════════════════════════╗\n# 5) CLEAN KAGGLE WORKSPACE (keep whisper_models)                    #\n# ╚══════════════════════════════════════════════════════════════════╝\nlog(\"🧹 Cleaning /kaggle/working (keeping whisper_models)\")\nfor item in WORKING.iterdir():\n    if item.name == \"whisper_models\":\n        continue\n    try:\n        shutil.rmtree(item) if item.is_dir() else item.unlink()\n    except Exception as e:\n        log(f\"  ✖ could not delete {item}: {e}\")\nlog(\"✅ All done\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T12:44:51.788280Z","iopub.execute_input":"2025-06-01T12:44:51.788594Z","iopub.status.idle":"2025-06-01T12:45:05.366542Z","shell.execute_reply.started":"2025-06-01T12:44:51.788574Z","shell.execute_reply":"2025-06-01T12:45:05.365839Z"}},"outputs":[{"name":"stdout","text":"[12:44:52] 📂 Drive subfolder '20230730 OpenHCI presentation' (id 1DzGdfx42hZ_Q8OEa6sWHrM0LPdntOaKx)\n[12:44:53]   ↳ uploaded 20230730 OpenHCI presentation.txt\n[12:44:54]   ↳ uploaded 20230730 OpenHCI presentation_parsed.txt\n[12:44:56]   ↳ uploaded 20230730 OpenHCI presentation.md\n[12:44:57]   ↳ moved 20230730 OpenHCI presentation.m4a → transcribed\n[12:44:57]   ✅ files verified\n[12:44:58] 📂 Drive subfolder '20230810 OpenHCI presentation feedback' (id 1CSfBnxnsWyQkf8rfDOk28RFVXbL45O1O)\n[12:45:00]   ↳ uploaded 20230810 OpenHCI presentation feedback.txt\n[12:45:01]   ↳ uploaded 20230810 OpenHCI presentation feedback_parsed.txt\n[12:45:02]   ↳ uploaded 20230810 OpenHCI presentation feedback.md\n[12:45:04]   ↳ moved 20230810 OpenHCI presentation feedback.m4a → transcribed\n[12:45:04]   ✅ files verified\n[12:45:05] 🧹 Cleaning /kaggle/working (keeping whisper_models)\n[12:45:05] ✅ All done\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"# ╔══════════════════════════════════════════════════════════════════╗\n#  EMAIL HACKMD LINKS  (only if something was uploaded)              #\n# ╚══════════════════════════════════════════════════════════════════╝\nfrom kaggle_secrets import UserSecretsClient\nimport smtplib\nfrom email.mime.multipart import MIMEMultipart\nfrom email.mime.text import MIMEText\nfrom email.header import Header\n\n# --- Skip entirely if no links were produced -----------------------\nif not (globals().get(\"shared_links\") and shared_links):\n    print(\"[INFO] No uploaded Markdown links – skipping email step.\")\nelse:\n    # --- Retrieve secrets ------------------------------------------\n    s = UserSecretsClient()\n    email_user = s.get_secret(\"EMAIL_USER\")\n    email_pass = s.get_secret(\"EMAIL_PASS\")\n    email_to   = s.get_secret(\"EMAIL_TO\")\n\n    if not all([email_user, email_pass, email_to]):\n        print(\"[WARN] Email secrets missing – email not sent.\")\n    else:\n        # --- Build email body --------------------------------------\n        subject = \"📝 Your Uploaded HackMD Speech Summaries\"\n        body_lines = [\n            \"Hello,\",\n            \"\",\n            \"Your audio files were transcribed with Whisper and\",\n            \"summarized using Gemini Flash 2.5. The summaries are now\",\n            \"available on HackMD:\",\n            \"\"\n        ] + [f\"- {link['title']}: {link['url']}\" for link in shared_links] + [\n            \"\",\n            \"If you have questions just reply to this email.\",\n            \"\",\n            \"Best regards,\",\n            \"Whisper-STT Bot\"\n        ]\n        body = \"\\n\".join(body_lines)\n\n        # --- Compose & send ---------------------------------------\n        msg             = MIMEMultipart()\n        msg[\"From\"]     = email_user\n        msg[\"To\"]       = email_to\n        msg[\"Subject\"]  = Header(subject, \"utf-8\")\n        msg.attach(MIMEText(body, \"plain\", \"utf-8\"))\n\n        try:\n            with smtplib.SMTP_SSL(\"smtp.gmail.com\", 465) as server:\n                server.login(email_user, email_pass)\n                server.send_message(msg)\n            print(\"[INFO] Email sent successfully.\")\n        except Exception as e:\n            print(f\"[ERROR] Email send failed: {e}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T12:45:13.608417Z","iopub.execute_input":"2025-06-01T12:45:13.608672Z","iopub.status.idle":"2025-06-01T12:45:16.088105Z","shell.execute_reply.started":"2025-06-01T12:45:13.608655Z","shell.execute_reply":"2025-06-01T12:45:16.087354Z"}},"outputs":[{"name":"stdout","text":"[INFO] Email sent successfully.\n","output_type":"stream"}],"execution_count":35}]}